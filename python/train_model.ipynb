{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1883399486541748\n",
      "0.9405457377433777\n"
     ]
    }
   ],
   "source": [
    "with np.load('dataset10000.npz') as data:\n",
    "    x_data,y_data = data['x'],data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    with open('minmax.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([np.min(data),np.max(data)])\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = NormalizeData(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 8)                 104       \n",
      "=================================================================\n",
      "Total params: 104\n",
      "Trainable params: 104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9529 - accuracy: 0.1663 - val_loss: 0.8378 - val_accuracy: 0.1710\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8339 - accuracy: 0.1655 - val_loss: 0.8369 - val_accuracy: 0.1685\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8329 - accuracy: 0.1670 - val_loss: 0.8372 - val_accuracy: 0.1705\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8318 - accuracy: 0.1666 - val_loss: 0.8354 - val_accuracy: 0.1755\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8314 - accuracy: 0.1659 - val_loss: 0.8338 - val_accuracy: 0.1795\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8308 - accuracy: 0.1675 - val_loss: 0.8346 - val_accuracy: 0.1790\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8305 - accuracy: 0.1670 - val_loss: 0.8337 - val_accuracy: 0.1825\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8304 - accuracy: 0.1676 - val_loss: 0.8326 - val_accuracy: 0.1805\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8303 - accuracy: 0.1708 - val_loss: 0.8337 - val_accuracy: 0.1840\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8303 - accuracy: 0.1671 - val_loss: 0.8335 - val_accuracy: 0.1765\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8300 - accuracy: 0.1714 - val_loss: 0.8347 - val_accuracy: 0.1775\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1714 - val_loss: 0.8325 - val_accuracy: 0.1735\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8301 - accuracy: 0.1705 - val_loss: 0.8334 - val_accuracy: 0.1815\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8298 - accuracy: 0.1680 - val_loss: 0.8336 - val_accuracy: 0.1870\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1695 - val_loss: 0.8321 - val_accuracy: 0.1810\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1660 - val_loss: 0.8326 - val_accuracy: 0.1835\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8298 - accuracy: 0.1686 - val_loss: 0.8337 - val_accuracy: 0.1735\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1708 - val_loss: 0.8323 - val_accuracy: 0.1745\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1716 - val_loss: 0.8330 - val_accuracy: 0.1740\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1681 - val_loss: 0.8327 - val_accuracy: 0.1855\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1708 - val_loss: 0.8332 - val_accuracy: 0.1835\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1686 - val_loss: 0.8333 - val_accuracy: 0.1870\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8298 - accuracy: 0.1664 - val_loss: 0.8320 - val_accuracy: 0.1810\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1680 - val_loss: 0.8341 - val_accuracy: 0.1830\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1678 - val_loss: 0.8334 - val_accuracy: 0.1830\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1669 - val_loss: 0.8331 - val_accuracy: 0.1790\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1674 - val_loss: 0.8337 - val_accuracy: 0.1805\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1709 - val_loss: 0.8319 - val_accuracy: 0.1730\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1657 - val_loss: 0.8330 - val_accuracy: 0.1870\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.1665 - val_loss: 0.8325 - val_accuracy: 0.1815\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1673 - val_loss: 0.8330 - val_accuracy: 0.1845\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1669 - val_loss: 0.8331 - val_accuracy: 0.1800\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1644 - val_loss: 0.8332 - val_accuracy: 0.1820\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1696 - val_loss: 0.8316 - val_accuracy: 0.1780\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1702 - val_loss: 0.8324 - val_accuracy: 0.1790\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1645 - val_loss: 0.8332 - val_accuracy: 0.1785\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1646 - val_loss: 0.8321 - val_accuracy: 0.1805\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1664 - val_loss: 0.8330 - val_accuracy: 0.1745\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1673 - val_loss: 0.8324 - val_accuracy: 0.1860\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1659 - val_loss: 0.8322 - val_accuracy: 0.1745\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1694 - val_loss: 0.8329 - val_accuracy: 0.1860\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1698 - val_loss: 0.8329 - val_accuracy: 0.1765\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1667 - val_loss: 0.8322 - val_accuracy: 0.1840\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1715 - val_loss: 0.8326 - val_accuracy: 0.1815\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1708 - val_loss: 0.8348 - val_accuracy: 0.1810\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1740 - val_loss: 0.8330 - val_accuracy: 0.1820\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1679 - val_loss: 0.8326 - val_accuracy: 0.1745\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1709 - val_loss: 0.8335 - val_accuracy: 0.1840\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1714 - val_loss: 0.8337 - val_accuracy: 0.1750\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1726 - val_loss: 0.8322 - val_accuracy: 0.1760\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1637 - val_loss: 0.8322 - val_accuracy: 0.1745\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1679 - val_loss: 0.8339 - val_accuracy: 0.1705\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1710 - val_loss: 0.8327 - val_accuracy: 0.1815\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1708 - val_loss: 0.8330 - val_accuracy: 0.1720\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1686 - val_loss: 0.8340 - val_accuracy: 0.1805\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1684 - val_loss: 0.8321 - val_accuracy: 0.1745\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1719 - val_loss: 0.8338 - val_accuracy: 0.1685\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1771 - val_loss: 0.8319 - val_accuracy: 0.1675\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.1709 - val_loss: 0.8334 - val_accuracy: 0.1845\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1650 - val_loss: 0.8332 - val_accuracy: 0.1735\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1723 - val_loss: 0.8328 - val_accuracy: 0.1775\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1674 - val_loss: 0.8333 - val_accuracy: 0.1850\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1691 - val_loss: 0.8334 - val_accuracy: 0.1740\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1705 - val_loss: 0.8324 - val_accuracy: 0.1725\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1688 - val_loss: 0.8330 - val_accuracy: 0.1875\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1681 - val_loss: 0.8336 - val_accuracy: 0.1820\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1650 - val_loss: 0.8326 - val_accuracy: 0.1665\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1689 - val_loss: 0.8331 - val_accuracy: 0.1860\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1695 - val_loss: 0.8335 - val_accuracy: 0.1865\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1686 - val_loss: 0.8322 - val_accuracy: 0.1870\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1713 - val_loss: 0.8325 - val_accuracy: 0.1720\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1655 - val_loss: 0.8320 - val_accuracy: 0.1750\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1702 - val_loss: 0.8323 - val_accuracy: 0.1650\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1685 - val_loss: 0.8347 - val_accuracy: 0.1655\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1684 - val_loss: 0.8326 - val_accuracy: 0.1870\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1744 - val_loss: 0.8321 - val_accuracy: 0.1865\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.1673 - val_loss: 0.8324 - val_accuracy: 0.1865\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1685 - val_loss: 0.8326 - val_accuracy: 0.1825\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1680 - val_loss: 0.8330 - val_accuracy: 0.1845\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1680 - val_loss: 0.8334 - val_accuracy: 0.1685\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1725 - val_loss: 0.8322 - val_accuracy: 0.1735\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1695 - val_loss: 0.8333 - val_accuracy: 0.1815\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1669 - val_loss: 0.8333 - val_accuracy: 0.1785\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1699 - val_loss: 0.8326 - val_accuracy: 0.1840\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1717 - val_loss: 0.8326 - val_accuracy: 0.1890\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1704 - val_loss: 0.8327 - val_accuracy: 0.1870\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1710 - val_loss: 0.8323 - val_accuracy: 0.1655\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1699 - val_loss: 0.8325 - val_accuracy: 0.1890\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1635 - val_loss: 0.8361 - val_accuracy: 0.1665\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1616 - val_loss: 0.8328 - val_accuracy: 0.1830\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1657 - val_loss: 0.8333 - val_accuracy: 0.1875\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1673 - val_loss: 0.8329 - val_accuracy: 0.1730\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1625 - val_loss: 0.8341 - val_accuracy: 0.1860\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1729 - val_loss: 0.8332 - val_accuracy: 0.1680\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1661 - val_loss: 0.8323 - val_accuracy: 0.1780\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1670 - val_loss: 0.8329 - val_accuracy: 0.1860\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1675 - val_loss: 0.8341 - val_accuracy: 0.1860\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1721 - val_loss: 0.8334 - val_accuracy: 0.1835\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1639 - val_loss: 0.8331 - val_accuracy: 0.1895\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1702 - val_loss: 0.8321 - val_accuracy: 0.1840\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1688 - val_loss: 0.8323 - val_accuracy: 0.1875\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1676 - val_loss: 0.8329 - val_accuracy: 0.1875\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1700 - val_loss: 0.8335 - val_accuracy: 0.1710\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1702 - val_loss: 0.8327 - val_accuracy: 0.1635\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1719 - val_loss: 0.8332 - val_accuracy: 0.1865\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1716 - val_loss: 0.8325 - val_accuracy: 0.1660\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1709 - val_loss: 0.8325 - val_accuracy: 0.1720\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1659 - val_loss: 0.8332 - val_accuracy: 0.1835\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1649 - val_loss: 0.8327 - val_accuracy: 0.1640\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1692 - val_loss: 0.8323 - val_accuracy: 0.1840\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1656 - val_loss: 0.8323 - val_accuracy: 0.1825\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1710 - val_loss: 0.8341 - val_accuracy: 0.1820\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8295 - accuracy: 0.1715 - val_loss: 0.8324 - val_accuracy: 0.1805\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1660 - val_loss: 0.8315 - val_accuracy: 0.1795\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1679 - val_loss: 0.8345 - val_accuracy: 0.1790\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8330 - val_accuracy: 0.1800\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1688 - val_loss: 0.8322 - val_accuracy: 0.1845\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1671 - val_loss: 0.8326 - val_accuracy: 0.1785\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1704 - val_loss: 0.8320 - val_accuracy: 0.1780\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1719 - val_loss: 0.8327 - val_accuracy: 0.1725\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1661 - val_loss: 0.8318 - val_accuracy: 0.1825\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1661 - val_loss: 0.8324 - val_accuracy: 0.1640\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1695 - val_loss: 0.8323 - val_accuracy: 0.1765\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1739 - val_loss: 0.8338 - val_accuracy: 0.1740\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1692 - val_loss: 0.8332 - val_accuracy: 0.1795\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1649 - val_loss: 0.8326 - val_accuracy: 0.1870\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1676 - val_loss: 0.8327 - val_accuracy: 0.1685\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1670 - val_loss: 0.8317 - val_accuracy: 0.1845\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1620 - val_loss: 0.8330 - val_accuracy: 0.1870\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1694 - val_loss: 0.8316 - val_accuracy: 0.1830\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1717 - val_loss: 0.8333 - val_accuracy: 0.1820\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1724 - val_loss: 0.8322 - val_accuracy: 0.1855\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1649 - val_loss: 0.8320 - val_accuracy: 0.1785\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1698 - val_loss: 0.8323 - val_accuracy: 0.1870\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1724 - val_loss: 0.8342 - val_accuracy: 0.1680\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8345 - val_accuracy: 0.1665\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1698 - val_loss: 0.8325 - val_accuracy: 0.1860\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8332 - val_accuracy: 0.1745\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1706 - val_loss: 0.8327 - val_accuracy: 0.1775\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1663 - val_loss: 0.8338 - val_accuracy: 0.1680\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8326 - val_accuracy: 0.1695\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1729 - val_loss: 0.8332 - val_accuracy: 0.1890\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1726 - val_loss: 0.8317 - val_accuracy: 0.1815\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1656 - val_loss: 0.8320 - val_accuracy: 0.1870\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1667 - val_loss: 0.8349 - val_accuracy: 0.1695\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1671 - val_loss: 0.8321 - val_accuracy: 0.1660\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1664 - val_loss: 0.8320 - val_accuracy: 0.1720\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1679 - val_loss: 0.8332 - val_accuracy: 0.1865\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1695 - val_loss: 0.8331 - val_accuracy: 0.1815\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1706 - val_loss: 0.8325 - val_accuracy: 0.1760\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1686 - val_loss: 0.8318 - val_accuracy: 0.1740\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1733 - val_loss: 0.8323 - val_accuracy: 0.1765\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1688 - val_loss: 0.8315 - val_accuracy: 0.1770\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1700 - val_loss: 0.8327 - val_accuracy: 0.1825\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1702 - val_loss: 0.8329 - val_accuracy: 0.1830\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1667 - val_loss: 0.8330 - val_accuracy: 0.1665\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1656 - val_loss: 0.8323 - val_accuracy: 0.1870\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1699 - val_loss: 0.8334 - val_accuracy: 0.1840\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1667 - val_loss: 0.8337 - val_accuracy: 0.1890\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1696 - val_loss: 0.8325 - val_accuracy: 0.1690\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1725 - val_loss: 0.8324 - val_accuracy: 0.1820\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1689 - val_loss: 0.8325 - val_accuracy: 0.1755\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1647 - val_loss: 0.8339 - val_accuracy: 0.1705\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1689 - val_loss: 0.8340 - val_accuracy: 0.1820\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1723 - val_loss: 0.8335 - val_accuracy: 0.1720\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1725 - val_loss: 0.8322 - val_accuracy: 0.1815\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1704 - val_loss: 0.8319 - val_accuracy: 0.1735\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1690 - val_loss: 0.8344 - val_accuracy: 0.1835\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1717 - val_loss: 0.8318 - val_accuracy: 0.1790\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1651 - val_loss: 0.8326 - val_accuracy: 0.1735\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1643 - val_loss: 0.8325 - val_accuracy: 0.1730\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1635 - val_loss: 0.8325 - val_accuracy: 0.1730\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1716 - val_loss: 0.8337 - val_accuracy: 0.1865\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1669 - val_loss: 0.8326 - val_accuracy: 0.1735\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1679 - val_loss: 0.8332 - val_accuracy: 0.1760\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1737 - val_loss: 0.8322 - val_accuracy: 0.1710\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1661 - val_loss: 0.8329 - val_accuracy: 0.1855\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1702 - val_loss: 0.8343 - val_accuracy: 0.1705\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1706 - val_loss: 0.8325 - val_accuracy: 0.1770\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1629 - val_loss: 0.8353 - val_accuracy: 0.1825\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1656 - val_loss: 0.8321 - val_accuracy: 0.1860\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1643 - val_loss: 0.8326 - val_accuracy: 0.1855\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1674 - val_loss: 0.8324 - val_accuracy: 0.1700\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1691 - val_loss: 0.8334 - val_accuracy: 0.1785\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1692 - val_loss: 0.8339 - val_accuracy: 0.1710\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1689 - val_loss: 0.8335 - val_accuracy: 0.1650\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1651 - val_loss: 0.8331 - val_accuracy: 0.1695\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1684 - val_loss: 0.8331 - val_accuracy: 0.1755\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1737 - val_loss: 0.8344 - val_accuracy: 0.1870\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1706 - val_loss: 0.8322 - val_accuracy: 0.1875\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1716 - val_loss: 0.8348 - val_accuracy: 0.1755\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1661 - val_loss: 0.8326 - val_accuracy: 0.1835\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1719 - val_loss: 0.8326 - val_accuracy: 0.1715\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1704 - val_loss: 0.8327 - val_accuracy: 0.1770\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1679 - val_loss: 0.8327 - val_accuracy: 0.1745\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1661 - val_loss: 0.8320 - val_accuracy: 0.1675\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1663 - val_loss: 0.8330 - val_accuracy: 0.1660\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1735 - val_loss: 0.8327 - val_accuracy: 0.1845\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1709 - val_loss: 0.8332 - val_accuracy: 0.1825\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1676 - val_loss: 0.8330 - val_accuracy: 0.1690\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1671 - val_loss: 0.8319 - val_accuracy: 0.1835\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1706 - val_loss: 0.8327 - val_accuracy: 0.1815\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1719 - val_loss: 0.8334 - val_accuracy: 0.1730\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1716 - val_loss: 0.8331 - val_accuracy: 0.1670\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1752 - val_loss: 0.8319 - val_accuracy: 0.1675\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1686 - val_loss: 0.8334 - val_accuracy: 0.1770\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1661 - val_loss: 0.8331 - val_accuracy: 0.1860\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1667 - val_loss: 0.8329 - val_accuracy: 0.1690\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1698 - val_loss: 0.8321 - val_accuracy: 0.1720\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1664 - val_loss: 0.8330 - val_accuracy: 0.1690\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1682 - val_loss: 0.8329 - val_accuracy: 0.1815\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1653 - val_loss: 0.8335 - val_accuracy: 0.1845\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1678 - val_loss: 0.8335 - val_accuracy: 0.1880\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1653 - val_loss: 0.8337 - val_accuracy: 0.1855\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8335 - val_accuracy: 0.1860\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1680 - val_loss: 0.8335 - val_accuracy: 0.1855\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1731 - val_loss: 0.8329 - val_accuracy: 0.1740\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8332 - val_accuracy: 0.1670\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1667 - val_loss: 0.8326 - val_accuracy: 0.1730\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1736 - val_loss: 0.8322 - val_accuracy: 0.1870\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1678 - val_loss: 0.8323 - val_accuracy: 0.1795\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1705 - val_loss: 0.8333 - val_accuracy: 0.1820\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1694 - val_loss: 0.8331 - val_accuracy: 0.1700\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1691 - val_loss: 0.8333 - val_accuracy: 0.1725\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8326 - val_accuracy: 0.1735\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1679 - val_loss: 0.8328 - val_accuracy: 0.1725\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1667 - val_loss: 0.8323 - val_accuracy: 0.1855\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1669 - val_loss: 0.8321 - val_accuracy: 0.1830\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1689 - val_loss: 0.8328 - val_accuracy: 0.1770\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1665 - val_loss: 0.8329 - val_accuracy: 0.1730\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1676 - val_loss: 0.8319 - val_accuracy: 0.1860\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1637 - val_loss: 0.8319 - val_accuracy: 0.1855\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1675 - val_loss: 0.8330 - val_accuracy: 0.1725\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1664 - val_loss: 0.8317 - val_accuracy: 0.1765\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1676 - val_loss: 0.8328 - val_accuracy: 0.1695\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8326 - val_accuracy: 0.1680\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1659 - val_loss: 0.8331 - val_accuracy: 0.1780\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8342 - val_accuracy: 0.1690\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1681 - val_loss: 0.8337 - val_accuracy: 0.1695\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1674 - val_loss: 0.8331 - val_accuracy: 0.1685\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1699 - val_loss: 0.8322 - val_accuracy: 0.1680\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1636 - val_loss: 0.8326 - val_accuracy: 0.1780\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1706 - val_loss: 0.8328 - val_accuracy: 0.1680\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1694 - val_loss: 0.8323 - val_accuracy: 0.1790\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1690 - val_loss: 0.8348 - val_accuracy: 0.1690\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1676 - val_loss: 0.8321 - val_accuracy: 0.1850\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1661 - val_loss: 0.8330 - val_accuracy: 0.1870\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1686 - val_loss: 0.8332 - val_accuracy: 0.1870\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1660 - val_loss: 0.8347 - val_accuracy: 0.1870\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1705 - val_loss: 0.8334 - val_accuracy: 0.1765\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1700 - val_loss: 0.8349 - val_accuracy: 0.1685\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1706 - val_loss: 0.8321 - val_accuracy: 0.1865\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.1688 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1710 - val_loss: 0.8334 - val_accuracy: 0.1755\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1726 - val_loss: 0.8323 - val_accuracy: 0.1715\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1706 - val_loss: 0.8340 - val_accuracy: 0.1715\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1650 - val_loss: 0.8334 - val_accuracy: 0.1690\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1695 - val_loss: 0.8340 - val_accuracy: 0.1870\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1704 - val_loss: 0.8325 - val_accuracy: 0.1840\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1685 - val_loss: 0.8329 - val_accuracy: 0.1875\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1756 - val_loss: 0.8337 - val_accuracy: 0.1685\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1686 - val_loss: 0.8331 - val_accuracy: 0.1780\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1734 - val_loss: 0.8331 - val_accuracy: 0.1700\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1695 - val_loss: 0.8333 - val_accuracy: 0.1825\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1723 - val_loss: 0.8337 - val_accuracy: 0.1825\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1678 - val_loss: 0.8329 - val_accuracy: 0.1840\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1691 - val_loss: 0.8322 - val_accuracy: 0.1690\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1694 - val_loss: 0.8324 - val_accuracy: 0.1820\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1695 - val_loss: 0.8319 - val_accuracy: 0.1680\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1708 - val_loss: 0.8332 - val_accuracy: 0.1845\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1678 - val_loss: 0.8328 - val_accuracy: 0.1725\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1665 - val_loss: 0.8319 - val_accuracy: 0.1780\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1709 - val_loss: 0.8321 - val_accuracy: 0.1840\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1666 - val_loss: 0.8316 - val_accuracy: 0.1820\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1702 - val_loss: 0.8344 - val_accuracy: 0.1705\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1671 - val_loss: 0.8332 - val_accuracy: 0.1840\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1655 - val_loss: 0.8327 - val_accuracy: 0.1860\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1643 - val_loss: 0.8332 - val_accuracy: 0.1695\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1710 - val_loss: 0.8339 - val_accuracy: 0.1855\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1685 - val_loss: 0.8335 - val_accuracy: 0.1705\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1702 - val_loss: 0.8324 - val_accuracy: 0.1695\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1716 - val_loss: 0.8319 - val_accuracy: 0.1725\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1719 - val_loss: 0.8325 - val_accuracy: 0.1690\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1670 - val_loss: 0.8332 - val_accuracy: 0.1680\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8330 - val_accuracy: 0.1840\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8285 - accuracy: 0.1671 - val_loss: 0.8323 - val_accuracy: 0.1855\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1688 - val_loss: 0.8334 - val_accuracy: 0.1705\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1710 - val_loss: 0.8320 - val_accuracy: 0.1770\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1710 - val_loss: 0.8336 - val_accuracy: 0.1870\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1669 - val_loss: 0.8315 - val_accuracy: 0.1700\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1751 - val_loss: 0.8320 - val_accuracy: 0.1860\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1680 - val_loss: 0.8324 - val_accuracy: 0.1720\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1665 - val_loss: 0.8324 - val_accuracy: 0.1830\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1640 - val_loss: 0.8327 - val_accuracy: 0.1685\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1696 - val_loss: 0.8323 - val_accuracy: 0.1860\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1719 - val_loss: 0.8325 - val_accuracy: 0.1700\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8323 - val_accuracy: 0.1820\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1685 - val_loss: 0.8363 - val_accuracy: 0.1850\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1689 - val_loss: 0.8328 - val_accuracy: 0.1695\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1733 - val_loss: 0.8328 - val_accuracy: 0.1870\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1649 - val_loss: 0.8332 - val_accuracy: 0.1690\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1702 - val_loss: 0.8318 - val_accuracy: 0.1845\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1713 - val_loss: 0.8322 - val_accuracy: 0.1785\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1704 - val_loss: 0.8333 - val_accuracy: 0.1860\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8336 - val_accuracy: 0.1830\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1680 - val_loss: 0.8319 - val_accuracy: 0.1835\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1684 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1719 - val_loss: 0.8318 - val_accuracy: 0.1705\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1643 - val_loss: 0.8337 - val_accuracy: 0.1780\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1698 - val_loss: 0.8320 - val_accuracy: 0.1835\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1680 - val_loss: 0.8341 - val_accuracy: 0.1810\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1655 - val_loss: 0.8323 - val_accuracy: 0.1785\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1714 - val_loss: 0.8321 - val_accuracy: 0.1860\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1715 - val_loss: 0.8322 - val_accuracy: 0.1820\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1701 - val_loss: 0.8328 - val_accuracy: 0.1670\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1680 - val_loss: 0.8326 - val_accuracy: 0.1835\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1723 - val_loss: 0.8330 - val_accuracy: 0.1705\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1675 - val_loss: 0.8324 - val_accuracy: 0.1710\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1681 - val_loss: 0.8328 - val_accuracy: 0.1675\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1676 - val_loss: 0.8331 - val_accuracy: 0.1815\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1690 - val_loss: 0.8318 - val_accuracy: 0.1855\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1717 - val_loss: 0.8324 - val_accuracy: 0.1765\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1713 - val_loss: 0.8324 - val_accuracy: 0.1775\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1686 - val_loss: 0.8328 - val_accuracy: 0.1765\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1692 - val_loss: 0.8332 - val_accuracy: 0.1795\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1700 - val_loss: 0.8322 - val_accuracy: 0.1845\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1692 - val_loss: 0.8332 - val_accuracy: 0.1805\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1664 - val_loss: 0.8324 - val_accuracy: 0.1850\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1682 - val_loss: 0.8330 - val_accuracy: 0.1785\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1739 - val_loss: 0.8332 - val_accuracy: 0.1700\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1698 - val_loss: 0.8345 - val_accuracy: 0.1855\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1759 - val_loss: 0.8330 - val_accuracy: 0.1685\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1678 - val_loss: 0.8334 - val_accuracy: 0.1700\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1671 - val_loss: 0.8342 - val_accuracy: 0.1835\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1673 - val_loss: 0.8325 - val_accuracy: 0.1865\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1729 - val_loss: 0.8323 - val_accuracy: 0.1710\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1694 - val_loss: 0.8330 - val_accuracy: 0.1850\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1729 - val_loss: 0.8320 - val_accuracy: 0.1730\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1686 - val_loss: 0.8323 - val_accuracy: 0.1665\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8339 - val_accuracy: 0.1835\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1692 - val_loss: 0.8331 - val_accuracy: 0.1855\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1659 - val_loss: 0.8334 - val_accuracy: 0.1790\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1656 - val_loss: 0.8320 - val_accuracy: 0.1805\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1685 - val_loss: 0.8336 - val_accuracy: 0.1735\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1671 - val_loss: 0.8321 - val_accuracy: 0.1865\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1675 - val_loss: 0.8319 - val_accuracy: 0.1695\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1685 - val_loss: 0.8329 - val_accuracy: 0.1870\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1694 - val_loss: 0.8324 - val_accuracy: 0.1735\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1678 - val_loss: 0.8326 - val_accuracy: 0.1775\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1656 - val_loss: 0.8320 - val_accuracy: 0.1655\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1740 - val_loss: 0.8331 - val_accuracy: 0.1840\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1696 - val_loss: 0.8331 - val_accuracy: 0.1675\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1710 - val_loss: 0.8321 - val_accuracy: 0.1810\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1684 - val_loss: 0.8328 - val_accuracy: 0.1805\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1663 - val_loss: 0.8333 - val_accuracy: 0.1845\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1704 - val_loss: 0.8320 - val_accuracy: 0.1860\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1711 - val_loss: 0.8322 - val_accuracy: 0.1835\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8323 - val_accuracy: 0.1830\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1675 - val_loss: 0.8328 - val_accuracy: 0.1765\n",
      "Epoch 360/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1671 - val_loss: 0.8326 - val_accuracy: 0.1720\n",
      "Epoch 361/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1699 - val_loss: 0.8328 - val_accuracy: 0.1695\n",
      "Epoch 362/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1704 - val_loss: 0.8322 - val_accuracy: 0.1685\n",
      "Epoch 363/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1645 - val_loss: 0.8325 - val_accuracy: 0.1705\n",
      "Epoch 364/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1714 - val_loss: 0.8332 - val_accuracy: 0.1805\n",
      "Epoch 365/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1673 - val_loss: 0.8327 - val_accuracy: 0.1710\n",
      "Epoch 366/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1610 - val_loss: 0.8322 - val_accuracy: 0.1845\n",
      "Epoch 367/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1645 - val_loss: 0.8347 - val_accuracy: 0.1805\n",
      "Epoch 368/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1713 - val_loss: 0.8330 - val_accuracy: 0.1745\n",
      "Epoch 369/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8321 - val_accuracy: 0.1805\n",
      "Epoch 370/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1711 - val_loss: 0.8329 - val_accuracy: 0.1820\n",
      "Epoch 371/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1674 - val_loss: 0.8319 - val_accuracy: 0.1705\n",
      "Epoch 372/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1710 - val_loss: 0.8319 - val_accuracy: 0.1825\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1694 - val_loss: 0.8336 - val_accuracy: 0.1680\n",
      "Epoch 374/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1680 - val_loss: 0.8329 - val_accuracy: 0.1860\n",
      "Epoch 375/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1675 - val_loss: 0.8320 - val_accuracy: 0.1835\n",
      "Epoch 376/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1678 - val_loss: 0.8343 - val_accuracy: 0.1860\n",
      "Epoch 377/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1670 - val_loss: 0.8320 - val_accuracy: 0.1820\n",
      "Epoch 378/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8328 - val_accuracy: 0.1845\n",
      "Epoch 379/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1654 - val_loss: 0.8335 - val_accuracy: 0.1710\n",
      "Epoch 380/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1735 - val_loss: 0.8329 - val_accuracy: 0.1660\n",
      "Epoch 381/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1685 - val_loss: 0.8320 - val_accuracy: 0.1710\n",
      "Epoch 382/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1709 - val_loss: 0.8322 - val_accuracy: 0.1855\n",
      "Epoch 383/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1661 - val_loss: 0.8325 - val_accuracy: 0.1680\n",
      "Epoch 384/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1706 - val_loss: 0.8317 - val_accuracy: 0.1820\n",
      "Epoch 385/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8344 - val_accuracy: 0.1835\n",
      "Epoch 386/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1651 - val_loss: 0.8337 - val_accuracy: 0.1700\n",
      "Epoch 387/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1694 - val_loss: 0.8330 - val_accuracy: 0.1825\n",
      "Epoch 388/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1694 - val_loss: 0.8336 - val_accuracy: 0.1670\n",
      "Epoch 389/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1720 - val_loss: 0.8328 - val_accuracy: 0.1820\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8321 - val_accuracy: 0.1845\n",
      "Epoch 391/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1692 - val_loss: 0.8324 - val_accuracy: 0.1845\n",
      "Epoch 392/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1710 - val_loss: 0.8321 - val_accuracy: 0.1860\n",
      "Epoch 393/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1720 - val_loss: 0.8321 - val_accuracy: 0.1765\n",
      "Epoch 394/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8324 - val_accuracy: 0.1810\n",
      "Epoch 395/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1690 - val_loss: 0.8335 - val_accuracy: 0.1815\n",
      "Epoch 396/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1680 - val_loss: 0.8338 - val_accuracy: 0.1715\n",
      "Epoch 397/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1655 - val_loss: 0.8355 - val_accuracy: 0.1755\n",
      "Epoch 398/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1717 - val_loss: 0.8322 - val_accuracy: 0.1815\n",
      "Epoch 399/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1682 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 400/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1696 - val_loss: 0.8336 - val_accuracy: 0.1870\n",
      "Epoch 401/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1667 - val_loss: 0.8329 - val_accuracy: 0.1840\n",
      "Epoch 402/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1701 - val_loss: 0.8333 - val_accuracy: 0.1720\n",
      "Epoch 403/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8323 - val_accuracy: 0.1820\n",
      "Epoch 404/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1647 - val_loss: 0.8322 - val_accuracy: 0.1710\n",
      "Epoch 405/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1733 - val_loss: 0.8341 - val_accuracy: 0.1855\n",
      "Epoch 406/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1766 - val_loss: 0.8330 - val_accuracy: 0.1810\n",
      "Epoch 407/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1661 - val_loss: 0.8325 - val_accuracy: 0.1695\n",
      "Epoch 408/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8330 - val_accuracy: 0.1825\n",
      "Epoch 409/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8336 - val_accuracy: 0.1700\n",
      "Epoch 410/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1673 - val_loss: 0.8333 - val_accuracy: 0.1730\n",
      "Epoch 411/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1635 - val_loss: 0.8324 - val_accuracy: 0.1715\n",
      "Epoch 412/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1731 - val_loss: 0.8318 - val_accuracy: 0.1820\n",
      "Epoch 413/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1667 - val_loss: 0.8316 - val_accuracy: 0.1860\n",
      "Epoch 414/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1655 - val_loss: 0.8353 - val_accuracy: 0.1735\n",
      "Epoch 415/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1646 - val_loss: 0.8320 - val_accuracy: 0.1770\n",
      "Epoch 416/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1686 - val_loss: 0.8348 - val_accuracy: 0.1690\n",
      "Epoch 417/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8330 - val_accuracy: 0.1690\n",
      "Epoch 418/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1663 - val_loss: 0.8344 - val_accuracy: 0.1740\n",
      "Epoch 419/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1725 - val_loss: 0.8325 - val_accuracy: 0.1855\n",
      "Epoch 420/1000\n",
      "800/800 [==============================] - 1s 999us/step - loss: 0.8291 - accuracy: 0.1724 - val_loss: 0.8326 - val_accuracy: 0.1845\n",
      "Epoch 421/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1671 - val_loss: 0.8321 - val_accuracy: 0.1870\n",
      "Epoch 422/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1665 - val_loss: 0.8318 - val_accuracy: 0.1845\n",
      "Epoch 423/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1715 - val_loss: 0.8322 - val_accuracy: 0.1675\n",
      "Epoch 424/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1691 - val_loss: 0.8325 - val_accuracy: 0.1650\n",
      "Epoch 425/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1644 - val_loss: 0.8332 - val_accuracy: 0.1850\n",
      "Epoch 426/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1646 - val_loss: 0.8323 - val_accuracy: 0.1705\n",
      "Epoch 427/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1720 - val_loss: 0.8325 - val_accuracy: 0.1690\n",
      "Epoch 428/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8333 - val_accuracy: 0.1670\n",
      "Epoch 429/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1726 - val_loss: 0.8328 - val_accuracy: 0.1820\n",
      "Epoch 430/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1630 - val_loss: 0.8341 - val_accuracy: 0.1720\n",
      "Epoch 431/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1669 - val_loss: 0.8336 - val_accuracy: 0.1685\n",
      "Epoch 432/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1644 - val_loss: 0.8326 - val_accuracy: 0.1700\n",
      "Epoch 433/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1689 - val_loss: 0.8325 - val_accuracy: 0.1840\n",
      "Epoch 434/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8341 - val_accuracy: 0.1870\n",
      "Epoch 435/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1720 - val_loss: 0.8322 - val_accuracy: 0.1700\n",
      "Epoch 436/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1679 - val_loss: 0.8317 - val_accuracy: 0.1690\n",
      "Epoch 437/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1735 - val_loss: 0.8327 - val_accuracy: 0.1685\n",
      "Epoch 438/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1696 - val_loss: 0.8326 - val_accuracy: 0.1835\n",
      "Epoch 439/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1731 - val_loss: 0.8331 - val_accuracy: 0.1645\n",
      "Epoch 440/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1698 - val_loss: 0.8331 - val_accuracy: 0.1705\n",
      "Epoch 441/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1680 - val_loss: 0.8342 - val_accuracy: 0.1655\n",
      "Epoch 442/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1702 - val_loss: 0.8319 - val_accuracy: 0.1800\n",
      "Epoch 443/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1690 - val_loss: 0.8335 - val_accuracy: 0.1740\n",
      "Epoch 444/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1729 - val_loss: 0.8341 - val_accuracy: 0.1810\n",
      "Epoch 445/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1701 - val_loss: 0.8333 - val_accuracy: 0.1785\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1643 - val_loss: 0.8349 - val_accuracy: 0.1875\n",
      "Epoch 447/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1639 - val_loss: 0.8339 - val_accuracy: 0.1825\n",
      "Epoch 448/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1699 - val_loss: 0.8330 - val_accuracy: 0.1725\n",
      "Epoch 449/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1686 - val_loss: 0.8335 - val_accuracy: 0.1685\n",
      "Epoch 450/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1679 - val_loss: 0.8325 - val_accuracy: 0.1685\n",
      "Epoch 451/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1664 - val_loss: 0.8327 - val_accuracy: 0.1665\n",
      "Epoch 452/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1678 - val_loss: 0.8322 - val_accuracy: 0.1835\n",
      "Epoch 453/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1678 - val_loss: 0.8324 - val_accuracy: 0.1815\n",
      "Epoch 454/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1686 - val_loss: 0.8343 - val_accuracy: 0.1730\n",
      "Epoch 455/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1661 - val_loss: 0.8356 - val_accuracy: 0.1875\n",
      "Epoch 456/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1686 - val_loss: 0.8333 - val_accuracy: 0.1690\n",
      "Epoch 457/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1671 - val_loss: 0.8323 - val_accuracy: 0.1685\n",
      "Epoch 458/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1729 - val_loss: 0.8320 - val_accuracy: 0.1745\n",
      "Epoch 459/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1673 - val_loss: 0.8335 - val_accuracy: 0.1830\n",
      "Epoch 460/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1717 - val_loss: 0.8327 - val_accuracy: 0.1865\n",
      "Epoch 461/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8319 - val_accuracy: 0.1665\n",
      "Epoch 462/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1698 - val_loss: 0.8324 - val_accuracy: 0.1845\n",
      "Epoch 463/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1716 - val_loss: 0.8319 - val_accuracy: 0.1810\n",
      "Epoch 464/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1711 - val_loss: 0.8334 - val_accuracy: 0.1765\n",
      "Epoch 465/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1708 - val_loss: 0.8332 - val_accuracy: 0.1815\n",
      "Epoch 466/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1629 - val_loss: 0.8328 - val_accuracy: 0.1795\n",
      "Epoch 467/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1691 - val_loss: 0.8336 - val_accuracy: 0.1825\n",
      "Epoch 468/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1674 - val_loss: 0.8321 - val_accuracy: 0.1680\n",
      "Epoch 469/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8330 - val_accuracy: 0.1740\n",
      "Epoch 470/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1729 - val_loss: 0.8324 - val_accuracy: 0.1790\n",
      "Epoch 471/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1680 - val_loss: 0.8318 - val_accuracy: 0.1730\n",
      "Epoch 472/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1699 - val_loss: 0.8331 - val_accuracy: 0.1845\n",
      "Epoch 473/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1726 - val_loss: 0.8332 - val_accuracy: 0.1825\n",
      "Epoch 474/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1678 - val_loss: 0.8337 - val_accuracy: 0.1860\n",
      "Epoch 475/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1698 - val_loss: 0.8335 - val_accuracy: 0.1870\n",
      "Epoch 476/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8323 - val_accuracy: 0.1665\n",
      "Epoch 477/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1706 - val_loss: 0.8322 - val_accuracy: 0.1830\n",
      "Epoch 478/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1629 - val_loss: 0.8327 - val_accuracy: 0.1850\n",
      "Epoch 479/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1690 - val_loss: 0.8323 - val_accuracy: 0.1855\n",
      "Epoch 480/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8331 - val_accuracy: 0.1820\n",
      "Epoch 481/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1681 - val_loss: 0.8325 - val_accuracy: 0.1855\n",
      "Epoch 482/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1720 - val_loss: 0.8320 - val_accuracy: 0.1875\n",
      "Epoch 483/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1670 - val_loss: 0.8336 - val_accuracy: 0.1670\n",
      "Epoch 484/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1669 - val_loss: 0.8329 - val_accuracy: 0.1850\n",
      "Epoch 485/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8321 - val_accuracy: 0.1830\n",
      "Epoch 486/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1653 - val_loss: 0.8347 - val_accuracy: 0.1690\n",
      "Epoch 487/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8333 - val_accuracy: 0.1830\n",
      "Epoch 488/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8333 - val_accuracy: 0.1680\n",
      "Epoch 489/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1745 - val_loss: 0.8324 - val_accuracy: 0.1680\n",
      "Epoch 490/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1689 - val_loss: 0.8339 - val_accuracy: 0.1705\n",
      "Epoch 491/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1691 - val_loss: 0.8334 - val_accuracy: 0.1875\n",
      "Epoch 492/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1726 - val_loss: 0.8333 - val_accuracy: 0.1810\n",
      "Epoch 493/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8318 - val_accuracy: 0.1845\n",
      "Epoch 494/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1700 - val_loss: 0.8323 - val_accuracy: 0.1740\n",
      "Epoch 495/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1702 - val_loss: 0.8322 - val_accuracy: 0.1865\n",
      "Epoch 496/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1645 - val_loss: 0.8324 - val_accuracy: 0.1730\n",
      "Epoch 497/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1709 - val_loss: 0.8331 - val_accuracy: 0.1855\n",
      "Epoch 498/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1655 - val_loss: 0.8330 - val_accuracy: 0.1705\n",
      "Epoch 499/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1637 - val_loss: 0.8318 - val_accuracy: 0.1690\n",
      "Epoch 500/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1654 - val_loss: 0.8349 - val_accuracy: 0.1850\n",
      "Epoch 501/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1723 - val_loss: 0.8333 - val_accuracy: 0.1795\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1675 - val_loss: 0.8342 - val_accuracy: 0.1690\n",
      "Epoch 503/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1657 - val_loss: 0.8326 - val_accuracy: 0.1720\n",
      "Epoch 504/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1692 - val_loss: 0.8328 - val_accuracy: 0.1795\n",
      "Epoch 505/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1665 - val_loss: 0.8322 - val_accuracy: 0.1810\n",
      "Epoch 506/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1674 - val_loss: 0.8327 - val_accuracy: 0.1695\n",
      "Epoch 507/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1682 - val_loss: 0.8326 - val_accuracy: 0.1850\n",
      "Epoch 508/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1724 - val_loss: 0.8339 - val_accuracy: 0.1845\n",
      "Epoch 509/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1689 - val_loss: 0.8336 - val_accuracy: 0.1830\n",
      "Epoch 510/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1630 - val_loss: 0.8335 - val_accuracy: 0.1820\n",
      "Epoch 511/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1686 - val_loss: 0.8320 - val_accuracy: 0.1725\n",
      "Epoch 512/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1649 - val_loss: 0.8349 - val_accuracy: 0.1745\n",
      "Epoch 513/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1643 - val_loss: 0.8331 - val_accuracy: 0.1815\n",
      "Epoch 514/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1620 - val_loss: 0.8322 - val_accuracy: 0.1705\n",
      "Epoch 515/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1711 - val_loss: 0.8333 - val_accuracy: 0.1875\n",
      "Epoch 516/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1713 - val_loss: 0.8325 - val_accuracy: 0.1840\n",
      "Epoch 517/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1680 - val_loss: 0.8323 - val_accuracy: 0.1730\n",
      "Epoch 518/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1622 - val_loss: 0.8330 - val_accuracy: 0.1715\n",
      "Epoch 519/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1665 - val_loss: 0.8325 - val_accuracy: 0.1690\n",
      "Epoch 520/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8342 - val_accuracy: 0.1725\n",
      "Epoch 521/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1671 - val_loss: 0.8333 - val_accuracy: 0.1810\n",
      "Epoch 522/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1686 - val_loss: 0.8346 - val_accuracy: 0.1850\n",
      "Epoch 523/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1675 - val_loss: 0.8323 - val_accuracy: 0.1855\n",
      "Epoch 524/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1699 - val_loss: 0.8327 - val_accuracy: 0.1665\n",
      "Epoch 525/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1660 - val_loss: 0.8322 - val_accuracy: 0.1805\n",
      "Epoch 526/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1682 - val_loss: 0.8339 - val_accuracy: 0.1840\n",
      "Epoch 527/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8322 - val_accuracy: 0.1860\n",
      "Epoch 528/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1725 - val_loss: 0.8335 - val_accuracy: 0.1650\n",
      "Epoch 529/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1702 - val_loss: 0.8336 - val_accuracy: 0.1685\n",
      "Epoch 530/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1719 - val_loss: 0.8347 - val_accuracy: 0.1650\n",
      "Epoch 531/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1690 - val_loss: 0.8325 - val_accuracy: 0.1675\n",
      "Epoch 532/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1673 - val_loss: 0.8345 - val_accuracy: 0.1845\n",
      "Epoch 533/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1667 - val_loss: 0.8336 - val_accuracy: 0.1700\n",
      "Epoch 534/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1659 - val_loss: 0.8326 - val_accuracy: 0.1670\n",
      "Epoch 535/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8324 - val_accuracy: 0.1685\n",
      "Epoch 536/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8328 - val_accuracy: 0.1715\n",
      "Epoch 537/1000\n",
      "800/800 [==============================] - 1s 1000us/step - loss: 0.8289 - accuracy: 0.1723 - val_loss: 0.8317 - val_accuracy: 0.1770\n",
      "Epoch 538/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1698 - val_loss: 0.8325 - val_accuracy: 0.1695\n",
      "Epoch 539/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1709 - val_loss: 0.8324 - val_accuracy: 0.1695\n",
      "Epoch 540/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1700 - val_loss: 0.8333 - val_accuracy: 0.1790\n",
      "Epoch 541/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1669 - val_loss: 0.8323 - val_accuracy: 0.1765\n",
      "Epoch 542/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1628 - val_loss: 0.8331 - val_accuracy: 0.1815\n",
      "Epoch 543/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1704 - val_loss: 0.8328 - val_accuracy: 0.1715\n",
      "Epoch 544/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1692 - val_loss: 0.8330 - val_accuracy: 0.1830\n",
      "Epoch 545/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1681 - val_loss: 0.8334 - val_accuracy: 0.1725\n",
      "Epoch 546/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1711 - val_loss: 0.8345 - val_accuracy: 0.1760\n",
      "Epoch 547/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1657 - val_loss: 0.8326 - val_accuracy: 0.1855\n",
      "Epoch 548/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1664 - val_loss: 0.8336 - val_accuracy: 0.1720\n",
      "Epoch 549/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1686 - val_loss: 0.8323 - val_accuracy: 0.1800\n",
      "Epoch 550/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1674 - val_loss: 0.8324 - val_accuracy: 0.1800\n",
      "Epoch 551/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1673 - val_loss: 0.8320 - val_accuracy: 0.1855\n",
      "Epoch 552/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1680 - val_loss: 0.8336 - val_accuracy: 0.1810\n",
      "Epoch 553/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1701 - val_loss: 0.8325 - val_accuracy: 0.1775\n",
      "Epoch 554/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1689 - val_loss: 0.8356 - val_accuracy: 0.1840\n",
      "Epoch 555/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1640 - val_loss: 0.8355 - val_accuracy: 0.1790\n",
      "Epoch 556/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1678 - val_loss: 0.8322 - val_accuracy: 0.1810\n",
      "Epoch 557/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8322 - val_accuracy: 0.1680\n",
      "Epoch 558/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1725 - val_loss: 0.8324 - val_accuracy: 0.1870\n",
      "Epoch 559/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1676 - val_loss: 0.8326 - val_accuracy: 0.1705\n",
      "Epoch 560/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1679 - val_loss: 0.8325 - val_accuracy: 0.1765\n",
      "Epoch 561/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1663 - val_loss: 0.8322 - val_accuracy: 0.1740\n",
      "Epoch 562/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1690 - val_loss: 0.8330 - val_accuracy: 0.1840\n",
      "Epoch 563/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1681 - val_loss: 0.8341 - val_accuracy: 0.1805\n",
      "Epoch 564/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8330 - val_accuracy: 0.1680\n",
      "Epoch 565/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1700 - val_loss: 0.8322 - val_accuracy: 0.1870\n",
      "Epoch 566/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1749 - val_loss: 0.8318 - val_accuracy: 0.1645\n",
      "Epoch 567/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1657 - val_loss: 0.8328 - val_accuracy: 0.1745\n",
      "Epoch 568/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1657 - val_loss: 0.8321 - val_accuracy: 0.1730\n",
      "Epoch 569/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1691 - val_loss: 0.8318 - val_accuracy: 0.1720\n",
      "Epoch 570/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1706 - val_loss: 0.8331 - val_accuracy: 0.1690\n",
      "Epoch 571/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1679 - val_loss: 0.8319 - val_accuracy: 0.1840\n",
      "Epoch 572/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1678 - val_loss: 0.8328 - val_accuracy: 0.1870\n",
      "Epoch 573/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8320 - val_accuracy: 0.1650\n",
      "Epoch 574/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1725 - val_loss: 0.8337 - val_accuracy: 0.1730\n",
      "Epoch 575/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1644 - val_loss: 0.8357 - val_accuracy: 0.1690\n",
      "Epoch 576/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1690 - val_loss: 0.8324 - val_accuracy: 0.1710\n",
      "Epoch 577/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1721 - val_loss: 0.8325 - val_accuracy: 0.1720\n",
      "Epoch 578/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1682 - val_loss: 0.8322 - val_accuracy: 0.1810\n",
      "Epoch 579/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1626 - val_loss: 0.8325 - val_accuracy: 0.1865\n",
      "Epoch 580/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1647 - val_loss: 0.8364 - val_accuracy: 0.1705\n",
      "Epoch 581/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1717 - val_loss: 0.8336 - val_accuracy: 0.1875\n",
      "Epoch 582/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1724 - val_loss: 0.8326 - val_accuracy: 0.1865\n",
      "Epoch 583/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1725 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 584/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8324 - val_accuracy: 0.1650\n",
      "Epoch 585/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8329 - val_accuracy: 0.1855\n",
      "Epoch 586/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1665 - val_loss: 0.8340 - val_accuracy: 0.1685\n",
      "Epoch 587/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1746 - val_loss: 0.8325 - val_accuracy: 0.1845\n",
      "Epoch 588/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1762 - val_loss: 0.8324 - val_accuracy: 0.1850\n",
      "Epoch 589/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1646 - val_loss: 0.8318 - val_accuracy: 0.1795\n",
      "Epoch 590/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1680 - val_loss: 0.8324 - val_accuracy: 0.1710\n",
      "Epoch 591/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1655 - val_loss: 0.8329 - val_accuracy: 0.1725\n",
      "Epoch 592/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1678 - val_loss: 0.8346 - val_accuracy: 0.1775\n",
      "Epoch 593/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1643 - val_loss: 0.8333 - val_accuracy: 0.1785\n",
      "Epoch 594/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1669 - val_loss: 0.8325 - val_accuracy: 0.1810\n",
      "Epoch 595/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1682 - val_loss: 0.8340 - val_accuracy: 0.1680\n",
      "Epoch 596/1000\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.8288 - accuracy: 0.1667 - val_loss: 0.8325 - val_accuracy: 0.1790\n",
      "Epoch 597/1000\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.8290 - accuracy: 0.1649 - val_loss: 0.8329 - val_accuracy: 0.1700\n",
      "Epoch 598/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1680 - val_loss: 0.8329 - val_accuracy: 0.1705\n",
      "Epoch 599/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1716 - val_loss: 0.8333 - val_accuracy: 0.1815\n",
      "Epoch 600/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1721 - val_loss: 0.8320 - val_accuracy: 0.1800\n",
      "Epoch 601/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1675 - val_loss: 0.8333 - val_accuracy: 0.1765\n",
      "Epoch 602/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1675 - val_loss: 0.8320 - val_accuracy: 0.1750\n",
      "Epoch 603/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1665 - val_loss: 0.8329 - val_accuracy: 0.1675\n",
      "Epoch 604/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1716 - val_loss: 0.8328 - val_accuracy: 0.1700\n",
      "Epoch 605/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1678 - val_loss: 0.8336 - val_accuracy: 0.1690\n",
      "Epoch 606/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1685 - val_loss: 0.8330 - val_accuracy: 0.1695\n",
      "Epoch 607/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1690 - val_loss: 0.8333 - val_accuracy: 0.1815\n",
      "Epoch 608/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1744 - val_loss: 0.8327 - val_accuracy: 0.1855\n",
      "Epoch 609/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8316 - val_accuracy: 0.1715\n",
      "Epoch 610/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1708 - val_loss: 0.8327 - val_accuracy: 0.1650\n",
      "Epoch 611/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8328 - val_accuracy: 0.1745\n",
      "Epoch 612/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1682 - val_loss: 0.8330 - val_accuracy: 0.1705\n",
      "Epoch 613/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1666 - val_loss: 0.8327 - val_accuracy: 0.1765\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8338 - val_accuracy: 0.1720\n",
      "Epoch 615/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1716 - val_loss: 0.8321 - val_accuracy: 0.1850\n",
      "Epoch 616/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1704 - val_loss: 0.8326 - val_accuracy: 0.1665\n",
      "Epoch 617/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1711 - val_loss: 0.8343 - val_accuracy: 0.1705\n",
      "Epoch 618/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1651 - val_loss: 0.8341 - val_accuracy: 0.1750\n",
      "Epoch 619/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1695 - val_loss: 0.8324 - val_accuracy: 0.1850\n",
      "Epoch 620/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1653 - val_loss: 0.8339 - val_accuracy: 0.1765\n",
      "Epoch 621/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1667 - val_loss: 0.8332 - val_accuracy: 0.1810\n",
      "Epoch 622/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1675 - val_loss: 0.8323 - val_accuracy: 0.1785\n",
      "Epoch 623/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1678 - val_loss: 0.8342 - val_accuracy: 0.1710\n",
      "Epoch 624/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1665 - val_loss: 0.8323 - val_accuracy: 0.1695\n",
      "Epoch 625/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1679 - val_loss: 0.8338 - val_accuracy: 0.1780\n",
      "Epoch 626/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1657 - val_loss: 0.8326 - val_accuracy: 0.1820\n",
      "Epoch 627/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1725 - val_loss: 0.8315 - val_accuracy: 0.1780\n",
      "Epoch 628/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1685 - val_loss: 0.8322 - val_accuracy: 0.1680\n",
      "Epoch 629/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1739 - val_loss: 0.8329 - val_accuracy: 0.1670\n",
      "Epoch 630/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1682 - val_loss: 0.8330 - val_accuracy: 0.1665\n",
      "Epoch 631/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8285 - accuracy: 0.1682 - val_loss: 0.8326 - val_accuracy: 0.1715\n",
      "Epoch 632/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1691 - val_loss: 0.8324 - val_accuracy: 0.1665\n",
      "Epoch 633/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1685 - val_loss: 0.8326 - val_accuracy: 0.1840\n",
      "Epoch 634/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8323 - val_accuracy: 0.1725\n",
      "Epoch 635/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8324 - val_accuracy: 0.1710\n",
      "Epoch 636/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1676 - val_loss: 0.8328 - val_accuracy: 0.1800\n",
      "Epoch 637/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1655 - val_loss: 0.8321 - val_accuracy: 0.1795\n",
      "Epoch 638/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1730 - val_loss: 0.8323 - val_accuracy: 0.1845\n",
      "Epoch 639/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1715 - val_loss: 0.8323 - val_accuracy: 0.1865\n",
      "Epoch 640/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1715 - val_loss: 0.8326 - val_accuracy: 0.1645\n",
      "Epoch 641/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8320 - val_accuracy: 0.1780\n",
      "Epoch 642/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1656 - val_loss: 0.8317 - val_accuracy: 0.1780\n",
      "Epoch 643/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1670 - val_loss: 0.8345 - val_accuracy: 0.1855\n",
      "Epoch 644/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1749 - val_loss: 0.8326 - val_accuracy: 0.1750\n",
      "Epoch 645/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1656 - val_loss: 0.8330 - val_accuracy: 0.1835\n",
      "Epoch 646/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1701 - val_loss: 0.8316 - val_accuracy: 0.1840\n",
      "Epoch 647/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1665 - val_loss: 0.8321 - val_accuracy: 0.1800\n",
      "Epoch 648/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1664 - val_loss: 0.8332 - val_accuracy: 0.1720\n",
      "Epoch 649/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1710 - val_loss: 0.8342 - val_accuracy: 0.1655\n",
      "Epoch 650/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1666 - val_loss: 0.8323 - val_accuracy: 0.1695\n",
      "Epoch 651/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8320 - val_accuracy: 0.1685\n",
      "Epoch 652/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1736 - val_loss: 0.8333 - val_accuracy: 0.1670\n",
      "Epoch 653/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1711 - val_loss: 0.8323 - val_accuracy: 0.1850\n",
      "Epoch 654/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1685 - val_loss: 0.8316 - val_accuracy: 0.1815\n",
      "Epoch 655/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1685 - val_loss: 0.8317 - val_accuracy: 0.1705\n",
      "Epoch 656/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1673 - val_loss: 0.8325 - val_accuracy: 0.1830\n",
      "Epoch 657/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8326 - val_accuracy: 0.1840\n",
      "Epoch 658/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1643 - val_loss: 0.8323 - val_accuracy: 0.1725\n",
      "Epoch 659/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1679 - val_loss: 0.8317 - val_accuracy: 0.1815\n",
      "Epoch 660/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1715 - val_loss: 0.8337 - val_accuracy: 0.1845\n",
      "Epoch 661/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1699 - val_loss: 0.8352 - val_accuracy: 0.1815\n",
      "Epoch 662/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1717 - val_loss: 0.8324 - val_accuracy: 0.1760\n",
      "Epoch 663/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1692 - val_loss: 0.8324 - val_accuracy: 0.1655\n",
      "Epoch 664/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1656 - val_loss: 0.8328 - val_accuracy: 0.1820\n",
      "Epoch 665/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1645 - val_loss: 0.8322 - val_accuracy: 0.1685\n",
      "Epoch 666/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1741 - val_loss: 0.8326 - val_accuracy: 0.1725\n",
      "Epoch 667/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1710 - val_loss: 0.8335 - val_accuracy: 0.1790\n",
      "Epoch 668/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1717 - val_loss: 0.8345 - val_accuracy: 0.1830\n",
      "Epoch 669/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1698 - val_loss: 0.8342 - val_accuracy: 0.1805\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1685 - val_loss: 0.8331 - val_accuracy: 0.1715\n",
      "Epoch 671/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1659 - val_loss: 0.8341 - val_accuracy: 0.1715\n",
      "Epoch 672/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1667 - val_loss: 0.8341 - val_accuracy: 0.1725\n",
      "Epoch 673/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1695 - val_loss: 0.8337 - val_accuracy: 0.1720\n",
      "Epoch 674/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1674 - val_loss: 0.8329 - val_accuracy: 0.1845\n",
      "Epoch 675/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1688 - val_loss: 0.8338 - val_accuracy: 0.1665\n",
      "Epoch 676/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1685 - val_loss: 0.8337 - val_accuracy: 0.1875\n",
      "Epoch 677/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8285 - accuracy: 0.1670 - val_loss: 0.8333 - val_accuracy: 0.1700\n",
      "Epoch 678/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1723 - val_loss: 0.8326 - val_accuracy: 0.1880\n",
      "Epoch 679/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1690 - val_loss: 0.8325 - val_accuracy: 0.1675\n",
      "Epoch 680/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1689 - val_loss: 0.8329 - val_accuracy: 0.1825\n",
      "Epoch 681/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1708 - val_loss: 0.8339 - val_accuracy: 0.1755\n",
      "Epoch 682/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1669 - val_loss: 0.8318 - val_accuracy: 0.1810\n",
      "Epoch 683/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1691 - val_loss: 0.8331 - val_accuracy: 0.1660\n",
      "Epoch 684/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1729 - val_loss: 0.8332 - val_accuracy: 0.1850\n",
      "Epoch 685/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1705 - val_loss: 0.8327 - val_accuracy: 0.1800\n",
      "Epoch 686/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1640 - val_loss: 0.8327 - val_accuracy: 0.1820\n",
      "Epoch 687/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1669 - val_loss: 0.8326 - val_accuracy: 0.1710\n",
      "Epoch 688/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1695 - val_loss: 0.8320 - val_accuracy: 0.1705\n",
      "Epoch 689/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1684 - val_loss: 0.8343 - val_accuracy: 0.1730\n",
      "Epoch 690/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1690 - val_loss: 0.8337 - val_accuracy: 0.1695\n",
      "Epoch 691/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1659 - val_loss: 0.8365 - val_accuracy: 0.1710\n",
      "Epoch 692/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8328 - val_accuracy: 0.1655\n",
      "Epoch 693/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1696 - val_loss: 0.8323 - val_accuracy: 0.1835\n",
      "Epoch 694/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1651 - val_loss: 0.8336 - val_accuracy: 0.1705\n",
      "Epoch 695/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1688 - val_loss: 0.8338 - val_accuracy: 0.1870\n",
      "Epoch 696/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1716 - val_loss: 0.8330 - val_accuracy: 0.1775\n",
      "Epoch 697/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1659 - val_loss: 0.8337 - val_accuracy: 0.1835\n",
      "Epoch 698/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1723 - val_loss: 0.8340 - val_accuracy: 0.1805\n",
      "Epoch 699/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1708 - val_loss: 0.8329 - val_accuracy: 0.1845\n",
      "Epoch 700/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1701 - val_loss: 0.8334 - val_accuracy: 0.1700\n",
      "Epoch 701/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1694 - val_loss: 0.8331 - val_accuracy: 0.1815\n",
      "Epoch 702/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1691 - val_loss: 0.8325 - val_accuracy: 0.1815\n",
      "Epoch 703/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1674 - val_loss: 0.8344 - val_accuracy: 0.1800\n",
      "Epoch 704/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1679 - val_loss: 0.8324 - val_accuracy: 0.1835\n",
      "Epoch 705/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1708 - val_loss: 0.8339 - val_accuracy: 0.1850\n",
      "Epoch 706/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1745 - val_loss: 0.8318 - val_accuracy: 0.1825\n",
      "Epoch 707/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1659 - val_loss: 0.8328 - val_accuracy: 0.1725\n",
      "Epoch 708/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1694 - val_loss: 0.8339 - val_accuracy: 0.1785\n",
      "Epoch 709/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1667 - val_loss: 0.8339 - val_accuracy: 0.1700\n",
      "Epoch 710/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1644 - val_loss: 0.8319 - val_accuracy: 0.1720\n",
      "Epoch 711/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1696 - val_loss: 0.8333 - val_accuracy: 0.1820\n",
      "Epoch 712/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1725 - val_loss: 0.8323 - val_accuracy: 0.1845\n",
      "Epoch 713/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1702 - val_loss: 0.8322 - val_accuracy: 0.1655\n",
      "Epoch 714/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8323 - val_accuracy: 0.1705\n",
      "Epoch 715/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1727 - val_loss: 0.8321 - val_accuracy: 0.1805\n",
      "Epoch 716/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1698 - val_loss: 0.8335 - val_accuracy: 0.1710\n",
      "Epoch 717/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1641 - val_loss: 0.8336 - val_accuracy: 0.1690\n",
      "Epoch 718/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8324 - val_accuracy: 0.1840\n",
      "Epoch 719/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1665 - val_loss: 0.8326 - val_accuracy: 0.1750\n",
      "Epoch 720/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1685 - val_loss: 0.8334 - val_accuracy: 0.1790\n",
      "Epoch 721/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1714 - val_loss: 0.8323 - val_accuracy: 0.1765\n",
      "Epoch 722/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1708 - val_loss: 0.8330 - val_accuracy: 0.1855\n",
      "Epoch 723/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1641 - val_loss: 0.8350 - val_accuracy: 0.1775\n",
      "Epoch 724/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8329 - val_accuracy: 0.1820\n",
      "Epoch 725/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8329 - val_accuracy: 0.1825\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1689 - val_loss: 0.8322 - val_accuracy: 0.1760\n",
      "Epoch 727/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1676 - val_loss: 0.8325 - val_accuracy: 0.1815\n",
      "Epoch 728/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1681 - val_loss: 0.8320 - val_accuracy: 0.1700\n",
      "Epoch 729/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1679 - val_loss: 0.8337 - val_accuracy: 0.1730\n",
      "Epoch 730/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1750 - val_loss: 0.8338 - val_accuracy: 0.1860\n",
      "Epoch 731/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1725 - val_loss: 0.8347 - val_accuracy: 0.1715\n",
      "Epoch 732/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1717 - val_loss: 0.8322 - val_accuracy: 0.1680\n",
      "Epoch 733/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1706 - val_loss: 0.8343 - val_accuracy: 0.1835\n",
      "Epoch 734/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1724 - val_loss: 0.8328 - val_accuracy: 0.1725\n",
      "Epoch 735/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1653 - val_loss: 0.8338 - val_accuracy: 0.1820\n",
      "Epoch 736/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1686 - val_loss: 0.8348 - val_accuracy: 0.1815\n",
      "Epoch 737/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1678 - val_loss: 0.8328 - val_accuracy: 0.1695\n",
      "Epoch 738/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1702 - val_loss: 0.8335 - val_accuracy: 0.1860\n",
      "Epoch 739/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8323 - val_accuracy: 0.1735\n",
      "Epoch 740/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1695 - val_loss: 0.8338 - val_accuracy: 0.1840\n",
      "Epoch 741/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1663 - val_loss: 0.8322 - val_accuracy: 0.1835\n",
      "Epoch 742/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1670 - val_loss: 0.8332 - val_accuracy: 0.1655\n",
      "Epoch 743/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1729 - val_loss: 0.8326 - val_accuracy: 0.1845\n",
      "Epoch 744/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8343 - val_accuracy: 0.1790\n",
      "Epoch 745/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1746 - val_loss: 0.8345 - val_accuracy: 0.1685\n",
      "Epoch 746/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1700 - val_loss: 0.8338 - val_accuracy: 0.1855\n",
      "Epoch 747/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1667 - val_loss: 0.8325 - val_accuracy: 0.1865\n",
      "Epoch 748/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1694 - val_loss: 0.8336 - val_accuracy: 0.1805\n",
      "Epoch 749/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1740 - val_loss: 0.8331 - val_accuracy: 0.1655\n",
      "Epoch 750/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1700 - val_loss: 0.8323 - val_accuracy: 0.1715\n",
      "Epoch 751/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1670 - val_loss: 0.8336 - val_accuracy: 0.1755\n",
      "Epoch 752/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1663 - val_loss: 0.8328 - val_accuracy: 0.1860\n",
      "Epoch 753/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1670 - val_loss: 0.8334 - val_accuracy: 0.1835\n",
      "Epoch 754/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.1705 - val_loss: 0.8323 - val_accuracy: 0.1670\n",
      "Epoch 755/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1702 - val_loss: 0.8318 - val_accuracy: 0.1810\n",
      "Epoch 756/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1711 - val_loss: 0.8320 - val_accuracy: 0.1870\n",
      "Epoch 757/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1656 - val_loss: 0.8322 - val_accuracy: 0.1840\n",
      "Epoch 758/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1675 - val_loss: 0.8329 - val_accuracy: 0.1855\n",
      "Epoch 759/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1640 - val_loss: 0.8350 - val_accuracy: 0.1795\n",
      "Epoch 760/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1657 - val_loss: 0.8345 - val_accuracy: 0.1820\n",
      "Epoch 761/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1678 - val_loss: 0.8338 - val_accuracy: 0.1840\n",
      "Epoch 762/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8337 - val_accuracy: 0.1685\n",
      "Epoch 763/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1709 - val_loss: 0.8331 - val_accuracy: 0.1800\n",
      "Epoch 764/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1684 - val_loss: 0.8330 - val_accuracy: 0.1865\n",
      "Epoch 765/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1656 - val_loss: 0.8325 - val_accuracy: 0.1835\n",
      "Epoch 766/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1667 - val_loss: 0.8320 - val_accuracy: 0.1685\n",
      "Epoch 767/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1680 - val_loss: 0.8343 - val_accuracy: 0.1815\n",
      "Epoch 768/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8326 - val_accuracy: 0.1775\n",
      "Epoch 769/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1675 - val_loss: 0.8323 - val_accuracy: 0.1695\n",
      "Epoch 770/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1691 - val_loss: 0.8336 - val_accuracy: 0.1660\n",
      "Epoch 771/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1646 - val_loss: 0.8339 - val_accuracy: 0.1670\n",
      "Epoch 772/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1635 - val_loss: 0.8321 - val_accuracy: 0.1730\n",
      "Epoch 773/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1655 - val_loss: 0.8331 - val_accuracy: 0.1700\n",
      "Epoch 774/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1699 - val_loss: 0.8335 - val_accuracy: 0.1705\n",
      "Epoch 775/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1698 - val_loss: 0.8352 - val_accuracy: 0.1855\n",
      "Epoch 776/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1673 - val_loss: 0.8332 - val_accuracy: 0.1870\n",
      "Epoch 777/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1674 - val_loss: 0.8321 - val_accuracy: 0.1685\n",
      "Epoch 778/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1714 - val_loss: 0.8339 - val_accuracy: 0.1815\n",
      "Epoch 779/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1679 - val_loss: 0.8335 - val_accuracy: 0.1730\n",
      "Epoch 780/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1682 - val_loss: 0.8330 - val_accuracy: 0.1755\n",
      "Epoch 781/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1716 - val_loss: 0.8335 - val_accuracy: 0.1835\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1660 - val_loss: 0.8329 - val_accuracy: 0.1795\n",
      "Epoch 783/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8325 - val_accuracy: 0.1660\n",
      "Epoch 784/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1655 - val_loss: 0.8336 - val_accuracy: 0.1765\n",
      "Epoch 785/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1669 - val_loss: 0.8319 - val_accuracy: 0.1650\n",
      "Epoch 786/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1696 - val_loss: 0.8329 - val_accuracy: 0.1805\n",
      "Epoch 787/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1711 - val_loss: 0.8343 - val_accuracy: 0.1870\n",
      "Epoch 788/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1679 - val_loss: 0.8325 - val_accuracy: 0.1825\n",
      "Epoch 789/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1696 - val_loss: 0.8326 - val_accuracy: 0.1685\n",
      "Epoch 790/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1778 - val_loss: 0.8343 - val_accuracy: 0.1685\n",
      "Epoch 791/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8332 - val_accuracy: 0.1715\n",
      "Epoch 792/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1632 - val_loss: 0.8324 - val_accuracy: 0.1785\n",
      "Epoch 793/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1714 - val_loss: 0.8336 - val_accuracy: 0.1740\n",
      "Epoch 794/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1674 - val_loss: 0.8322 - val_accuracy: 0.1685\n",
      "Epoch 795/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1734 - val_loss: 0.8318 - val_accuracy: 0.1810\n",
      "Epoch 796/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1659 - val_loss: 0.8334 - val_accuracy: 0.1705\n",
      "Epoch 797/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1702 - val_loss: 0.8325 - val_accuracy: 0.1720\n",
      "Epoch 798/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1688 - val_loss: 0.8334 - val_accuracy: 0.1750\n",
      "Epoch 799/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1706 - val_loss: 0.8326 - val_accuracy: 0.1695\n",
      "Epoch 800/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1641 - val_loss: 0.8324 - val_accuracy: 0.1840\n",
      "Epoch 801/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1696 - val_loss: 0.8326 - val_accuracy: 0.1785\n",
      "Epoch 802/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8333 - val_accuracy: 0.1735\n",
      "Epoch 803/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1651 - val_loss: 0.8317 - val_accuracy: 0.1845\n",
      "Epoch 804/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1689 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 805/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1641 - val_loss: 0.8337 - val_accuracy: 0.1715\n",
      "Epoch 806/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1681 - val_loss: 0.8327 - val_accuracy: 0.1665\n",
      "Epoch 807/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8339 - val_accuracy: 0.1795\n",
      "Epoch 808/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1674 - val_loss: 0.8322 - val_accuracy: 0.1805\n",
      "Epoch 809/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1674 - val_loss: 0.8340 - val_accuracy: 0.1690\n",
      "Epoch 810/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1710 - val_loss: 0.8322 - val_accuracy: 0.1870\n",
      "Epoch 811/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1701 - val_loss: 0.8354 - val_accuracy: 0.1780\n",
      "Epoch 812/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1708 - val_loss: 0.8318 - val_accuracy: 0.1670\n",
      "Epoch 813/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1690 - val_loss: 0.8325 - val_accuracy: 0.1830\n",
      "Epoch 814/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8343 - val_accuracy: 0.1825\n",
      "Epoch 815/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1674 - val_loss: 0.8331 - val_accuracy: 0.1785\n",
      "Epoch 816/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1699 - val_loss: 0.8343 - val_accuracy: 0.1725\n",
      "Epoch 817/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8319 - val_accuracy: 0.1720\n",
      "Epoch 818/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1660 - val_loss: 0.8326 - val_accuracy: 0.1660\n",
      "Epoch 819/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1632 - val_loss: 0.8340 - val_accuracy: 0.1850\n",
      "Epoch 820/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1681 - val_loss: 0.8319 - val_accuracy: 0.1830\n",
      "Epoch 821/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1667 - val_loss: 0.8323 - val_accuracy: 0.1695\n",
      "Epoch 822/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1673 - val_loss: 0.8345 - val_accuracy: 0.1680\n",
      "Epoch 823/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1695 - val_loss: 0.8328 - val_accuracy: 0.1725\n",
      "Epoch 824/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1702 - val_loss: 0.8334 - val_accuracy: 0.1660\n",
      "Epoch 825/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1713 - val_loss: 0.8330 - val_accuracy: 0.1815\n",
      "Epoch 826/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1694 - val_loss: 0.8321 - val_accuracy: 0.1695\n",
      "Epoch 827/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1715 - val_loss: 0.8336 - val_accuracy: 0.1820\n",
      "Epoch 828/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1720 - val_loss: 0.8322 - val_accuracy: 0.1815\n",
      "Epoch 829/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1681 - val_loss: 0.8325 - val_accuracy: 0.1735\n",
      "Epoch 830/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1696 - val_loss: 0.8326 - val_accuracy: 0.1865\n",
      "Epoch 831/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1641 - val_loss: 0.8333 - val_accuracy: 0.1755\n",
      "Epoch 832/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1701 - val_loss: 0.8334 - val_accuracy: 0.1695\n",
      "Epoch 833/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1667 - val_loss: 0.8329 - val_accuracy: 0.1675\n",
      "Epoch 834/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1660 - val_loss: 0.8324 - val_accuracy: 0.1700\n",
      "Epoch 835/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1665 - val_loss: 0.8321 - val_accuracy: 0.1855\n",
      "Epoch 836/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1709 - val_loss: 0.8332 - val_accuracy: 0.1840\n",
      "Epoch 837/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1686 - val_loss: 0.8328 - val_accuracy: 0.1755\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1689 - val_loss: 0.8353 - val_accuracy: 0.1725\n",
      "Epoch 839/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1701 - val_loss: 0.8339 - val_accuracy: 0.1680\n",
      "Epoch 840/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8345 - val_accuracy: 0.1695\n",
      "Epoch 841/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1645 - val_loss: 0.8324 - val_accuracy: 0.1715\n",
      "Epoch 842/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1650 - val_loss: 0.8331 - val_accuracy: 0.1830\n",
      "Epoch 843/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8332 - val_accuracy: 0.1770\n",
      "Epoch 844/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1714 - val_loss: 0.8324 - val_accuracy: 0.1820\n",
      "Epoch 845/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1682 - val_loss: 0.8334 - val_accuracy: 0.1715\n",
      "Epoch 846/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1717 - val_loss: 0.8315 - val_accuracy: 0.1705\n",
      "Epoch 847/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1689 - val_loss: 0.8327 - val_accuracy: 0.1800\n",
      "Epoch 848/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1741 - val_loss: 0.8336 - val_accuracy: 0.1675\n",
      "Epoch 849/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8330 - val_accuracy: 0.1650\n",
      "Epoch 850/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1704 - val_loss: 0.8342 - val_accuracy: 0.1670\n",
      "Epoch 851/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1704 - val_loss: 0.8323 - val_accuracy: 0.1735\n",
      "Epoch 852/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1681 - val_loss: 0.8321 - val_accuracy: 0.1790\n",
      "Epoch 853/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1700 - val_loss: 0.8329 - val_accuracy: 0.1840\n",
      "Epoch 854/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1680 - val_loss: 0.8323 - val_accuracy: 0.1715\n",
      "Epoch 855/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1706 - val_loss: 0.8326 - val_accuracy: 0.1825\n",
      "Epoch 856/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1725 - val_loss: 0.8334 - val_accuracy: 0.1670\n",
      "Epoch 857/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1664 - val_loss: 0.8347 - val_accuracy: 0.1720\n",
      "Epoch 858/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8335 - val_accuracy: 0.1715\n",
      "Epoch 859/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1681 - val_loss: 0.8328 - val_accuracy: 0.1865\n",
      "Epoch 860/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1716 - val_loss: 0.8351 - val_accuracy: 0.1825\n",
      "Epoch 861/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1702 - val_loss: 0.8324 - val_accuracy: 0.1790\n",
      "Epoch 862/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1641 - val_loss: 0.8332 - val_accuracy: 0.1840\n",
      "Epoch 863/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1656 - val_loss: 0.8337 - val_accuracy: 0.1740\n",
      "Epoch 864/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1717 - val_loss: 0.8321 - val_accuracy: 0.1720\n",
      "Epoch 865/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1698 - val_loss: 0.8325 - val_accuracy: 0.1825\n",
      "Epoch 866/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1673 - val_loss: 0.8329 - val_accuracy: 0.1720\n",
      "Epoch 867/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1694 - val_loss: 0.8343 - val_accuracy: 0.1770\n",
      "Epoch 868/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1717 - val_loss: 0.8319 - val_accuracy: 0.1830\n",
      "Epoch 869/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1717 - val_loss: 0.8349 - val_accuracy: 0.1710\n",
      "Epoch 870/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1708 - val_loss: 0.8336 - val_accuracy: 0.1840\n",
      "Epoch 871/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1704 - val_loss: 0.8320 - val_accuracy: 0.1845\n",
      "Epoch 872/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1685 - val_loss: 0.8337 - val_accuracy: 0.1870\n",
      "Epoch 873/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1692 - val_loss: 0.8322 - val_accuracy: 0.1795\n",
      "Epoch 874/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1680 - val_loss: 0.8322 - val_accuracy: 0.1775\n",
      "Epoch 875/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8325 - val_accuracy: 0.1720\n",
      "Epoch 876/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1678 - val_loss: 0.8319 - val_accuracy: 0.1860\n",
      "Epoch 877/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1675 - val_loss: 0.8342 - val_accuracy: 0.1720\n",
      "Epoch 878/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1686 - val_loss: 0.8326 - val_accuracy: 0.1865\n",
      "Epoch 879/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1670 - val_loss: 0.8349 - val_accuracy: 0.1665\n",
      "Epoch 880/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1726 - val_loss: 0.8332 - val_accuracy: 0.1710\n",
      "Epoch 881/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1680 - val_loss: 0.8334 - val_accuracy: 0.1760\n",
      "Epoch 882/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1647 - val_loss: 0.8333 - val_accuracy: 0.1795\n",
      "Epoch 883/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1696 - val_loss: 0.8332 - val_accuracy: 0.1715\n",
      "Epoch 884/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1734 - val_loss: 0.8325 - val_accuracy: 0.1810\n",
      "Epoch 885/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1656 - val_loss: 0.8321 - val_accuracy: 0.1695\n",
      "Epoch 886/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1678 - val_loss: 0.8325 - val_accuracy: 0.1715\n",
      "Epoch 887/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1641 - val_loss: 0.8333 - val_accuracy: 0.1815\n",
      "Epoch 888/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1702 - val_loss: 0.8332 - val_accuracy: 0.1800\n",
      "Epoch 889/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8320 - val_accuracy: 0.1820\n",
      "Epoch 890/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1646 - val_loss: 0.8328 - val_accuracy: 0.1720\n",
      "Epoch 891/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1696 - val_loss: 0.8320 - val_accuracy: 0.1800\n",
      "Epoch 892/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1656 - val_loss: 0.8332 - val_accuracy: 0.1820\n",
      "Epoch 893/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1702 - val_loss: 0.8347 - val_accuracy: 0.1690\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1727 - val_loss: 0.8330 - val_accuracy: 0.1850\n",
      "Epoch 895/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1743 - val_loss: 0.8319 - val_accuracy: 0.1795\n",
      "Epoch 896/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1709 - val_loss: 0.8332 - val_accuracy: 0.1715\n",
      "Epoch 897/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1635 - val_loss: 0.8332 - val_accuracy: 0.1695\n",
      "Epoch 898/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1695 - val_loss: 0.8343 - val_accuracy: 0.1805\n",
      "Epoch 899/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1634 - val_loss: 0.8339 - val_accuracy: 0.1700\n",
      "Epoch 900/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1740 - val_loss: 0.8339 - val_accuracy: 0.1765\n",
      "Epoch 901/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.1649 - val_loss: 0.8334 - val_accuracy: 0.1725\n",
      "Epoch 902/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1661 - val_loss: 0.8329 - val_accuracy: 0.1830\n",
      "Epoch 903/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1739 - val_loss: 0.8326 - val_accuracy: 0.1845\n",
      "Epoch 904/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1649 - val_loss: 0.8327 - val_accuracy: 0.1685\n",
      "Epoch 905/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1684 - val_loss: 0.8320 - val_accuracy: 0.1740\n",
      "Epoch 906/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8333 - val_accuracy: 0.1695\n",
      "Epoch 907/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1713 - val_loss: 0.8331 - val_accuracy: 0.1695\n",
      "Epoch 908/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1699 - val_loss: 0.8334 - val_accuracy: 0.1720\n",
      "Epoch 909/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1737 - val_loss: 0.8332 - val_accuracy: 0.1675\n",
      "Epoch 910/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1686 - val_loss: 0.8328 - val_accuracy: 0.1740\n",
      "Epoch 911/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1655 - val_loss: 0.8323 - val_accuracy: 0.1670\n",
      "Epoch 912/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1696 - val_loss: 0.8327 - val_accuracy: 0.1660\n",
      "Epoch 913/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8321 - val_accuracy: 0.1815\n",
      "Epoch 914/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1692 - val_loss: 0.8334 - val_accuracy: 0.1720\n",
      "Epoch 915/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1706 - val_loss: 0.8323 - val_accuracy: 0.1705\n",
      "Epoch 916/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1717 - val_loss: 0.8331 - val_accuracy: 0.1655\n",
      "Epoch 917/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1666 - val_loss: 0.8321 - val_accuracy: 0.1710\n",
      "Epoch 918/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1710 - val_loss: 0.8336 - val_accuracy: 0.1710\n",
      "Epoch 919/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8348 - val_accuracy: 0.1835\n",
      "Epoch 920/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1689 - val_loss: 0.8338 - val_accuracy: 0.1655\n",
      "Epoch 921/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1714 - val_loss: 0.8328 - val_accuracy: 0.1830\n",
      "Epoch 922/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1715 - val_loss: 0.8325 - val_accuracy: 0.1765\n",
      "Epoch 923/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1739 - val_loss: 0.8327 - val_accuracy: 0.1805\n",
      "Epoch 924/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1692 - val_loss: 0.8334 - val_accuracy: 0.1725\n",
      "Epoch 925/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1673 - val_loss: 0.8340 - val_accuracy: 0.1835\n",
      "Epoch 926/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1665 - val_loss: 0.8317 - val_accuracy: 0.1705\n",
      "Epoch 927/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8321 - val_accuracy: 0.1835\n",
      "Epoch 928/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1656 - val_loss: 0.8331 - val_accuracy: 0.1695\n",
      "Epoch 929/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1700 - val_loss: 0.8326 - val_accuracy: 0.1765\n",
      "Epoch 930/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1713 - val_loss: 0.8327 - val_accuracy: 0.1645\n",
      "Epoch 931/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1619 - val_loss: 0.8326 - val_accuracy: 0.1680\n",
      "Epoch 932/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1715 - val_loss: 0.8328 - val_accuracy: 0.1695\n",
      "Epoch 933/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1710 - val_loss: 0.8330 - val_accuracy: 0.1835\n",
      "Epoch 934/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1715 - val_loss: 0.8335 - val_accuracy: 0.1790\n",
      "Epoch 935/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1625 - val_loss: 0.8319 - val_accuracy: 0.1720\n",
      "Epoch 936/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1713 - val_loss: 0.8332 - val_accuracy: 0.1670\n",
      "Epoch 937/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8325 - val_accuracy: 0.1665\n",
      "Epoch 938/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1685 - val_loss: 0.8337 - val_accuracy: 0.1840\n",
      "Epoch 939/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1649 - val_loss: 0.8323 - val_accuracy: 0.1825\n",
      "Epoch 940/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1659 - val_loss: 0.8329 - val_accuracy: 0.1840\n",
      "Epoch 941/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1710 - val_loss: 0.8340 - val_accuracy: 0.1695\n",
      "Epoch 942/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1713 - val_loss: 0.8340 - val_accuracy: 0.1740\n",
      "Epoch 943/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1700 - val_loss: 0.8330 - val_accuracy: 0.1800\n",
      "Epoch 944/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1664 - val_loss: 0.8326 - val_accuracy: 0.1725\n",
      "Epoch 945/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1666 - val_loss: 0.8315 - val_accuracy: 0.1730\n",
      "Epoch 946/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1664 - val_loss: 0.8328 - val_accuracy: 0.1835\n",
      "Epoch 947/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1704 - val_loss: 0.8330 - val_accuracy: 0.1645\n",
      "Epoch 948/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1656 - val_loss: 0.8334 - val_accuracy: 0.1765\n",
      "Epoch 949/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1671 - val_loss: 0.8321 - val_accuracy: 0.1700\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1724 - val_loss: 0.8326 - val_accuracy: 0.1670\n",
      "Epoch 951/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1700 - val_loss: 0.8324 - val_accuracy: 0.1825\n",
      "Epoch 952/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1691 - val_loss: 0.8319 - val_accuracy: 0.1695\n",
      "Epoch 953/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1702 - val_loss: 0.8322 - val_accuracy: 0.1780\n",
      "Epoch 954/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1701 - val_loss: 0.8329 - val_accuracy: 0.1805\n",
      "Epoch 955/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1690 - val_loss: 0.8333 - val_accuracy: 0.1690\n",
      "Epoch 956/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1721 - val_loss: 0.8325 - val_accuracy: 0.1820\n",
      "Epoch 957/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1692 - val_loss: 0.8338 - val_accuracy: 0.1710\n",
      "Epoch 958/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1724 - val_loss: 0.8325 - val_accuracy: 0.1675\n",
      "Epoch 959/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1705 - val_loss: 0.8324 - val_accuracy: 0.1700\n",
      "Epoch 960/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1667 - val_loss: 0.8329 - val_accuracy: 0.1870\n",
      "Epoch 961/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1682 - val_loss: 0.8331 - val_accuracy: 0.1700\n",
      "Epoch 962/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1684 - val_loss: 0.8335 - val_accuracy: 0.1655\n",
      "Epoch 963/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1701 - val_loss: 0.8323 - val_accuracy: 0.1840\n",
      "Epoch 964/1000\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.8287 - accuracy: 0.1760 - val_loss: 0.8323 - val_accuracy: 0.1825\n",
      "Epoch 965/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1714 - val_loss: 0.8347 - val_accuracy: 0.1835\n",
      "Epoch 966/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1679 - val_loss: 0.8340 - val_accuracy: 0.1660\n",
      "Epoch 967/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1711 - val_loss: 0.8334 - val_accuracy: 0.1725\n",
      "Epoch 968/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1689 - val_loss: 0.8323 - val_accuracy: 0.1810\n",
      "Epoch 969/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1688 - val_loss: 0.8321 - val_accuracy: 0.1705\n",
      "Epoch 970/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1721 - val_loss: 0.8322 - val_accuracy: 0.1725\n",
      "Epoch 971/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1646 - val_loss: 0.8325 - val_accuracy: 0.1660\n",
      "Epoch 972/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1701 - val_loss: 0.8336 - val_accuracy: 0.1815\n",
      "Epoch 973/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1731 - val_loss: 0.8321 - val_accuracy: 0.1780\n",
      "Epoch 974/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1695 - val_loss: 0.8316 - val_accuracy: 0.1870\n",
      "Epoch 975/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1720 - val_loss: 0.8319 - val_accuracy: 0.1775\n",
      "Epoch 976/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1645 - val_loss: 0.8344 - val_accuracy: 0.1750\n",
      "Epoch 977/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1682 - val_loss: 0.8332 - val_accuracy: 0.1865\n",
      "Epoch 978/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8322 - val_accuracy: 0.1840\n",
      "Epoch 979/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1702 - val_loss: 0.8355 - val_accuracy: 0.1700\n",
      "Epoch 980/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1688 - val_loss: 0.8349 - val_accuracy: 0.1800\n",
      "Epoch 981/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1657 - val_loss: 0.8349 - val_accuracy: 0.1870\n",
      "Epoch 982/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1699 - val_loss: 0.8335 - val_accuracy: 0.1830\n",
      "Epoch 983/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1727 - val_loss: 0.8327 - val_accuracy: 0.1860\n",
      "Epoch 984/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1679 - val_loss: 0.8332 - val_accuracy: 0.1720\n",
      "Epoch 985/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1699 - val_loss: 0.8341 - val_accuracy: 0.1685\n",
      "Epoch 986/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.1646 - val_loss: 0.8349 - val_accuracy: 0.1865\n",
      "Epoch 987/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8323 - val_accuracy: 0.1735\n",
      "Epoch 988/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1666 - val_loss: 0.8321 - val_accuracy: 0.1700\n",
      "Epoch 989/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1663 - val_loss: 0.8335 - val_accuracy: 0.1815\n",
      "Epoch 990/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1660 - val_loss: 0.8326 - val_accuracy: 0.1690\n",
      "Epoch 991/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1674 - val_loss: 0.8330 - val_accuracy: 0.1745\n",
      "Epoch 992/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8290 - accuracy: 0.1698 - val_loss: 0.8329 - val_accuracy: 0.1710\n",
      "Epoch 993/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1653 - val_loss: 0.8332 - val_accuracy: 0.1830\n",
      "Epoch 994/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1724 - val_loss: 0.8333 - val_accuracy: 0.1730\n",
      "Epoch 995/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1674 - val_loss: 0.8331 - val_accuracy: 0.1680\n",
      "Epoch 996/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1676 - val_loss: 0.8322 - val_accuracy: 0.1870\n",
      "Epoch 997/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.1719 - val_loss: 0.8328 - val_accuracy: 0.1835\n",
      "Epoch 998/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.1709 - val_loss: 0.8334 - val_accuracy: 0.1815\n",
      "Epoch 999/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.1656 - val_loss: 0.8332 - val_accuracy: 0.1845\n",
      "Epoch 1000/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8291 - accuracy: 0.1690 - val_loss: 0.8325 - val_accuracy: 0.1685\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# normLayer = keras.layers.experimental.preprocessing.Normalization(mean= mean , variance=variance)\n",
    "# normLayer.adapt(x_train)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "#                 normLayer,\n",
    "                Dense(8, input_shape = (12,), activation='linear'),\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer = keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs = 1000, batch_size = 10 , validation_data = (x_test, y_test))\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
